[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bruno Gondim",
    "section": "",
    "text": "Estudante de graduação no bacharel de Estatística na Universidade de Brasília - UnB\nAqui estão aplicações pessoais de machine learning, ciência de dados e estatística. Me interesso também em programação, estrutura e modelagem de dados. Acredito em um mundo mais igualitário e justo."
  },
  {
    "objectID": "index.html#formação",
    "href": "index.html#formação",
    "title": "Bruno Gondim",
    "section": "Formação",
    "text": "Formação\nUniversidade de Brasília (UnB) | Distrito Federal, Brasil | Bacharel em Estatística | Ago 2015 - presente"
  },
  {
    "objectID": "index.html#experiência",
    "href": "index.html#experiência",
    "title": "Bruno Gondim",
    "section": "Experiência",
    "text": "Experiência\nGerente de projetos na ESTAT - Jan 2022 - Jan 2023\nEstagiário STF | Núcleo de análise de dados e estatística (NUADE) | Jul 2023 - presente"
  },
  {
    "objectID": "presentations/nlp/index.html#introdução",
    "href": "presentations/nlp/index.html#introdução",
    "title": "Agrupador de processos de controle concentrado",
    "section": "Introdução",
    "text": "Introdução\n\n\nNo campo do direito, a aplicação de técnicas estatísticas vem sendo testada em diversos âmbitos, inclusive no Supremo Tribunal Federal do Brasil.\nÉ de interesse do tribunal a aplicação destas técnicas para agrupamento de processos. Um agrupador poderia ajudar a identificar processos semelhantes, trabalho este feito manualmente.\nEste trabalho busca estudar e aplicar algumas destas técnicas para o desenvolvimento de uma aplicação prática no STF, com objetivo de agrupar processos de controle concentrado."
  },
  {
    "objectID": "presentations/nlp/index.html#objetivos",
    "href": "presentations/nlp/index.html#objetivos",
    "title": "Agrupador de processos de controle concentrado",
    "section": "Objetivos",
    "text": "Objetivos\n\nO objetivo deste trabalho é formular um agregador de processos de controle concentrado, que são processos que tratam da constitucionalidade de leis e atos normativos. Constituem o dito controle concentrado os processos do Supremo Tribunal Federal das seguintes classes:\n\n\nADI (Ação Direta de Inconstitucionalidade)\nADC (Ação Declaratória de Constitucionalidade)\nADPF (Arguição de Descumprimento de Preceito Fundamental)\nADO (Ação Direta de Inconstitucionalidade por Omissão)"
  },
  {
    "objectID": "presentations/nlp/index.html#objetivos-1",
    "href": "presentations/nlp/index.html#objetivos-1",
    "title": "Agrupador de processos de controle concentrado",
    "section": "Objetivos",
    "text": "Objetivos\n\nO agrupador fornecerá subsídios aos responsáveis pelo encaminhamento dos processos que chegam ao STF, visando reduzir o trabalho mecânico humano.\nDos objetivos específicos, espera-se:\n\n\nProcessar os dados utilizando técnicas de Processamento de Linguagem Natural (PLN), transformando petições iniciais de processos em vetores numéricos;\nComparar técnicas de agrupamento;\nAvaliar a similaridade entre processos em recortes temporais distintos;\nEstudar técnicas de PLN, análise multivariada e visualização de dados."
  },
  {
    "objectID": "presentations/nlp/index.html#metodologia",
    "href": "presentations/nlp/index.html#metodologia",
    "title": "Agrupador de processos de controle concentrado",
    "section": "Metodologia",
    "text": "Metodologia\nTendo os dados e o modelo pré-treinado para vetorização, os códigos Python e R para a vetorização dos textos, e posterior análise, são da seguinte forma:\n\n\n\n# Módulos\nimport polars\nimport gensim\nfrom gensim.models.doc2vec import Doc2Vec\n\n# Função\ndef infer_vector(text):\n    return model.infer_vector(text.split())\n\n# Modelo pré-treinado para Embedding\nmodel = gensim.models.Doc2Vec.load(\"modelo.model\")\n\n# Dados\ndf = polars.read_csv(\"dados.csv\",columns=[1,3,4])\n\n# Saída: DataFrame com duas colunas: Texto original e vetor Embedding correspondente.\ndf = df.with_columns_seq(polars.col(\"texto\").apply(infer_vector).alias(\"vetor\"))\n\n\n\n# Pacote\nlibrary(reticulate)\n\n# Definindo o ambiente virtual python\nreticulate::use_condaenv(\"TCC\")\n\n# Executando o script python\nreticulate::source_python(\"script.py\")\n\n# Ajustando o dataframe trazido do python para formato R mais adequado\ndf &lt;- as.data.frame(do.call(rbind, lapply(a, function(x) c(x[[1]], x[[2]]))), stringsAsFactors = FALSE)"
  },
  {
    "objectID": "presentations/nlp/index.html#metodologia-1",
    "href": "presentations/nlp/index.html#metodologia-1",
    "title": "Agrupador de processos de controle concentrado",
    "section": "Metodologia",
    "text": "Metodologia\n\nPassos para a construção do agregador:\n\n\n\n\n\nObtenção dos dados:\n\n\nOs dados foram disponibilizados pelo STF (mas estão disponíveis publicamente no Portal do STF.).\n\n\nVetorização (incluindo ocerização e processamento do texto PDF):\n\n\nEste módulo foi fornecido pelo STF (dados em formato CSV)"
  },
  {
    "objectID": "presentations/nlp/index.html#metodologia-2",
    "href": "presentations/nlp/index.html#metodologia-2",
    "title": "Agrupador de processos de controle concentrado",
    "section": "Metodologia",
    "text": "Metodologia\n\n\n\n\nDefinir recortes temporais para a agregação:\n\n\nPor conta da natureza cíclica dos processos que compõem o acervo do STF, é necessário um sistema de atualização constante para uma aplicação prática.\nSerá realizado o agrupamento com dados em recortes temporais distintos, e, em cada recorte, será avaliada a similaridade entre os processos em tramitação naquela data."
  },
  {
    "objectID": "presentations/nlp/index.html#metodologia-3",
    "href": "presentations/nlp/index.html#metodologia-3",
    "title": "Agrupador de processos de controle concentrado",
    "section": "Metodologia",
    "text": "Metodologia\n\n\n\n\nAplicação de medidas de distância para comparar a similaridade dos processos (distância euclidiana, distância do cosseno etc)."
  },
  {
    "objectID": "presentations/nlp/index.html#metodologia-4",
    "href": "presentations/nlp/index.html#metodologia-4",
    "title": "Agrupador de processos de controle concentrado",
    "section": "Metodologia",
    "text": "Metodologia\n\n\n\n\nPara a formação dos agrupamentos, serão utilizadas técnicas de agrupamento hierárquico e não-hierárquico baseadas nas distâncias calculadas.\n\n\nPara a visualização dos dados, serão estudadas técnicas como dendrogramas e t-SNE."
  },
  {
    "objectID": "presentations/nlp/index.html#cronograma",
    "href": "presentations/nlp/index.html#cronograma",
    "title": "Agrupador de processos de controle concentrado",
    "section": "Cronograma",
    "text": "Cronograma\n\n\nCronograma TCC 1\n\n\nAtividades\nMar\nAbr\nMai\nJun\nJul\n\n\n\n\nEscolha do tema a ser abordado.\n\n\n\n\n\n\n\nLevantamento de bibliografia relacionada ao tema.\n\n\n\n\n\n\n\nDefinição do recorte temporal com a AAJ do STF.\n\n\n\n\n\n\n\nSolicitação dos dados para a STI do STF.\n\n\n\n\n\n\n\nSolicitação dos algoritmos à STI do STF.\n\n\n\n\n\n\n\nRevisão de literatura.\n\n\n\n\n\n\n\nDesenvolvimento da proposta de projeto.\n\n\n\n\n\n\n\nAnálise preliminar do banco de dados.\n\n\n\n\n\n\n\nEntrega da proposta do projeto.\n\n\n\n\n\n\n\nElaboração da apresentação da proposta.\n\n\n\n\n\n\n\nManipulação do banco de dados.\n\n\n\n\n\n\n\nAnálise do banco de dados.\n\n\n\n\n\n\n\nElaboração do relatório parcial.\n\n\n\n\n\n\n\nEntrega do relatório parcial a Professora Orientadora.\n\n\n\n\n\n\n\nCorreção do relatório parcial.\n\n\n\n\n\n\n\nEntrega do relatório parcial a banca."
  },
  {
    "objectID": "presentations/nlp/index.html#cronograma-1",
    "href": "presentations/nlp/index.html#cronograma-1",
    "title": "Agrupador de processos de controle concentrado",
    "section": "Cronograma",
    "text": "Cronograma\n\n\nCronograma TCC 2\n\n\nAtividades\nAgo\nSet\nOut\nNov\nDez\n\n\n\n\nDesenvolvimento do modelo e da aplicação.\n\n\n\n\n\n\n\nElaboração do relatório final.\n\n\n\n\n\n\n\nEntrega do relatório final a Professora Orientadora.\n\n\n\n\n\n\n\nCorreção do relatório final.\n\n\n\n\n\n\n\nEntrega do relatório final para a banca."
  },
  {
    "objectID": "presentations/nlp/index.html#referências",
    "href": "presentations/nlp/index.html#referências",
    "title": "Agrupador de processos de controle concentrado",
    "section": "Referências",
    "text": "Referências\n\nARTES, R.; BARROSO, L. P. Métodos multivariados de análise estatística. [S.l.]: São Paulo: Blucher, 2023.\nEVERITT, B.; SKRONDAL, A. The cambridge dictionary of statistics. [S.l.]: Cambridge University Press, 2010. v. 4.\nFREITAS, L. J. G. et al. Catboost algorithm application in legal texts and un 2030 agenda. Revista de Informatica Teórica e Aplicada - RITA - ISSN 2175-2745. Vol. 30, Num. 02 (2023) 51-58, 2023.\nFREITAS, L. J. G. et al. Text clustering applied to data augmentation in legal contexts. arXiv preprint arXiv:2404.08683, 2024.\nJOHNSON, R. A.; WICHERN, D. W. Applied Multivariate Statistical Analysis. [S.l.]: 6. ed.[S.l.]:Prentice Hall, 2007.\nKAUFMAN, L.; ROUSSEEUW, P. J. Finding groups in data: an introduction to cluster analysis. [S.l.]: John Wiley & Sons, 1990.\nLECUN, Y. et al. Gradient-based learning applied to document recognition. Proceedings of the IEEE, Ieee, v. 86, n. 11, p. 2278–2324, 1998.\nMAATEN, L. Van der; HINTON, G. Visualizing data using t-sne. Journal of machine learning research, v. 9, n. 11, 2008.\nMACQUEEN, J. et al. Some methods for classification and analysis of multivariate observations. [S.l.], 1967. v. 1. 281–297 p.\nMORETTIN, P. A.; SINGER, J. M. Estatística e Ciência de Dados. [S.l.]: LTC, 2021.\nRICARDO, B.-Y.; BERTHIER, R.-N. Modern information retrieval: the concepts and technology behind search. [S.l.]: New Jersey, USA: Addi-son-Wesley Professional, 2011.\nvon Borries, G.; WANG, H. Partition clustering of high dimensional low sample size data based on p-values. Computational statistics & data analysis, v. 53, n. 12, p. 3987-3998, 2009.\n\n\n\n\n\nDepartamento de estatística - UnB"
  },
  {
    "objectID": "presentations/random_forest/apresentacao.html#introdução",
    "href": "presentations/random_forest/apresentacao.html#introdução",
    "title": "Técnica Random Forest em árvores de decisão",
    "section": "Introdução",
    "text": "Introdução\n\nO que é floresta aleatória?\n\nFloresta aleatória é um algoritmo de Machine learning, utilizado para realizar predições, que combina o resultado de múltiplas árvores de decisão criadas aleatoriamente com o objetivo de diminuir a variância e o viés no contexto dos métodos de árvores."
  },
  {
    "objectID": "presentations/random_forest/apresentacao.html#introdução-1",
    "href": "presentations/random_forest/apresentacao.html#introdução-1",
    "title": "Técnica Random Forest em árvores de decisão",
    "section": "Introdução",
    "text": "Introdução\n\nÁrvore de decisão\n\nUma árvore de decisão é a forma mais básica entre os métodos baseados em árvore, muito utilizada em regressão e classificação, uma árvore de decisão consiste em segmentar o espaço composto pelas variáveis preditoras em regiões mais simples, nos quais a média (se a variável resposta for quantitativa) é utilizada como valor predito ou (caso categorizado) a classe da variável resposta com maior frequência, os modelos de árvores de decisão são atraentes pela simplicidade e fácil interpretação, contudo não possuem a precisão que outros métodos de classificação ou regressão alcançam."
  },
  {
    "objectID": "presentations/random_forest/apresentacao.html#vantagens-e-desvantagens",
    "href": "presentations/random_forest/apresentacao.html#vantagens-e-desvantagens",
    "title": "Técnica Random Forest em árvores de decisão",
    "section": "Vantagens e desvantagens",
    "text": "Vantagens e desvantagens\n\nsobre árvore de decisão:\n\n\n\nVantagens\n\n\nSão facilmente explicaveis;\nPodem ser representadas graficamente com fácil interpretação;\nPodem manupular preditores qualitativos sem a necessidade de variáveis dummy.\n\n\n\nDesvantagens\n\n\nNão possuem o mesmo nível de precisão preditiva como outros modelos de regressão e classificação;\nNão são robustas, ou seja, uma pequena mudança nos dados pode gerar uma grande mudança na árvore de estimação final."
  },
  {
    "objectID": "presentations/random_forest/apresentacao.html#motivação",
    "href": "presentations/random_forest/apresentacao.html#motivação",
    "title": "Técnica Random Forest em árvores de decisão",
    "section": "Motivação",
    "text": "Motivação\nUma forma de superar a baixa precisão das árvores de decisão é a utilização de métodos agregadoes que ajustam modelos poderosos, como floresta aleatória, que consegue uma grande melhoria no poder de predição mesmo comparando com outros modelos de classificação."
  },
  {
    "objectID": "presentations/random_forest/apresentacao.html#procedimento",
    "href": "presentations/random_forest/apresentacao.html#procedimento",
    "title": "Técnica Random Forest em árvores de decisão",
    "section": "Procedimento",
    "text": "Procedimento\n\n\nComo na técnica bagging, construímos várias árvores a partir das amostras bootstrap do conjunto de testes.\nNa construção de cada árvore, cada vez que uma divisão (ou corte) é considerada para alguma árvore, uma seleção aleatória dos preditores é escolhida como candidatos dos cortes ao invés de todos os preditores como normalmente é feito.\nEssa abordagem tem como propósito reduzir a correlação entre as árvores, reduzindo a variância quando tiramos a média das árvores, já que a média tende a ser menor quando temos menor correlação entre as árvores.\nA escolha do número de preditores que serão selecionados para cada corte, é tipicamente escolhida pela raiz quadrada do número total de preditores.\nFlorestas aleatórias fornecem uma melhoria em relação ao método bagging, já que a correlação entre as árvores diminui."
  },
  {
    "objectID": "presentations/random_forest/apresentacao.html#considerações",
    "href": "presentations/random_forest/apresentacao.html#considerações",
    "title": "Técnica Random Forest em árvores de decisão",
    "section": "Considerações",
    "text": "Considerações\n\nDe forma geral, pode-se dizer que o procedimento introduz mais aleatoriedade e diversidade no processo de construção em relação ao método bagging.\nIntuitivamente, a utilização de florestas aleatórias para tomada de decisão corresponde à síntese da opinião de indivíduos com diferentes fontes de informação.\nEm geral, florestas aleatórias produzem resultados menos variáveis em relação ao método bagging, já que nesse método as árvores geradas podem ser muito semelhantes, dependendo de preditores fortes, o que não contribui para redução de variabilidade das predições, o que não acontece com florestas aleatórias."
  },
  {
    "objectID": "presentations/random_forest/apresentacao.html#rotina",
    "href": "presentations/random_forest/apresentacao.html#rotina",
    "title": "Técnica Random Forest em árvores de decisão",
    "section": "Rotina",
    "text": "Rotina\nUma rotina minimalista de classificação via Random Forest em R pode ser executada da seguinte forma:\n\n\n\nlibrary(randomForest)\n\ndata &lt;- iris\n\ndata$Species &lt;- as.factor(data$Species)\n\nset.seed(150167636)\nind &lt;- sample(2, nrow(data), replace = TRUE,\n              prob = c(0.7, 0.3))\ntrain &lt;- data[ind==1,]\ntest &lt;- data[ind==2,]\n\nrf &lt;- randomForest(Species~., data=train, proximity=TRUE)\n\n\n\n\n\nCall:\n randomForest(formula = Species ~ ., data = train, proximity = TRUE) \n               Type of random forest: classification\n                     Number of trees: 500\nNo. of variables tried at each split: 2\n\n        OOB estimate of  error rate: 6.36%\nConfusion matrix:\n           setosa versicolor virginica class.error\nsetosa         33          0         0  0.00000000\nversicolor      0         36         3  0.07692308\nvirginica       0          4        34  0.10526316"
  },
  {
    "objectID": "presentations/random_forest/apresentacao.html#resultados",
    "href": "presentations/random_forest/apresentacao.html#resultados",
    "title": "Técnica Random Forest em árvores de decisão",
    "section": "Resultados",
    "text": "Resultados\nPodemos acessar os resultados do modelo no objeto rf\n\n\nTeste do modelo no conjunto de treino:\n\nlibrary(caret)\n\np1 &lt;- predict(rf, train)\nconfusionMatrix(p1, train$ Species)\n\nConfusion Matrix and Statistics\n\n            Reference\nPrediction   setosa versicolor virginica\n  setosa         33          0         0\n  versicolor      0         39         0\n  virginica       0          0        38\n\nOverall Statistics\n                                    \n               Accuracy : 1         \n                 95% CI : (0.967, 1)\n    No Information Rate : 0.3545    \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16 \n                                    \n                  Kappa : 1         \n                                    \n Mcnemar's Test P-Value : NA        \n\nStatistics by Class:\n\n                     Class: setosa Class: versicolor Class: virginica\nSensitivity                    1.0            1.0000           1.0000\nSpecificity                    1.0            1.0000           1.0000\nPos Pred Value                 1.0            1.0000           1.0000\nNeg Pred Value                 1.0            1.0000           1.0000\nPrevalence                     0.3            0.3545           0.3455\nDetection Rate                 0.3            0.3545           0.3455\nDetection Prevalence           0.3            0.3545           0.3455\nBalanced Accuracy              1.0            1.0000           1.0000\n\n\n\nValidação do modelo nos dados de teste:\n\np2 &lt;- predict(rf, test)\nconfusionMatrix(p2, test$ Species)\n\nConfusion Matrix and Statistics\n\n            Reference\nPrediction   setosa versicolor virginica\n  setosa         17          0         0\n  versicolor      0         10         2\n  virginica       0          1        10\n\nOverall Statistics\n                                          \n               Accuracy : 0.925           \n                 95% CI : (0.7961, 0.9843)\n    No Information Rate : 0.425           \n    P-Value [Acc &gt; NIR] : 3.546e-11       \n                                          \n                  Kappa : 0.8854          \n                                          \n Mcnemar's Test P-Value : NA              \n\nStatistics by Class:\n\n                     Class: setosa Class: versicolor Class: virginica\nSensitivity                  1.000            0.9091           0.8333\nSpecificity                  1.000            0.9310           0.9643\nPos Pred Value               1.000            0.8333           0.9091\nNeg Pred Value               1.000            0.9643           0.9310\nPrevalence                   0.425            0.2750           0.3000\nDetection Rate               0.425            0.2500           0.2500\nDetection Prevalence         0.425            0.3000           0.2750\nBalanced Accuracy            1.000            0.9201           0.8988"
  },
  {
    "objectID": "presentations/random_forest/apresentacao.html#parâmetros",
    "href": "presentations/random_forest/apresentacao.html#parâmetros",
    "title": "Técnica Random Forest em árvores de decisão",
    "section": "Parâmetros",
    "text": "Parâmetros\n\nA função randomForest do pacote homônimo tem uma série de parâmetros opcionais além do mínimo obrigatório, que seria o modelo e os dados. O mais importante destes parâmetros é o ntree, que por default é 500 e em geral deve-se utilizar o máximo possível tal que execute em um tempo aceitável. Em geral, o restante dos parâmetros deve ser deixado em default.\nNeste caso, o modelo foi extremamente eficiente mesmo na versão minimalista"
  },
  {
    "objectID": "presentations/random_forest/apresentacao.html#fine-tuning",
    "href": "presentations/random_forest/apresentacao.html#fine-tuning",
    "title": "Técnica Random Forest em árvores de decisão",
    "section": "Fine tuning",
    "text": "Fine tuning\n\nSe for o caso, também podemos fazer o fine-tuning dos parâmetros do modelo\n\n\n\n\nt &lt;- tuneRF(train[,-5], train[,5],\n       stepFactor = 0.5,\n       plot = TRUE,\n       ntreeTry = 150,\n       trace = TRUE,\n       improve = 0.05)\n\nmtry = 2  OOB error = 5.45% \nSearching left ...\nmtry = 4    OOB error = 5.45% \n0 0.05 \nSearching right ...\nmtry = 1    OOB error = 5.45% \n0 0.05 \n\n\n\n\n\n\n\n\n\n\n\nhist(treesize(rf),\n     main = \"No. of Nodes for the Trees\",\n     col = \"green\")"
  },
  {
    "objectID": "presentations/random_forest/apresentacao.html#importâncias",
    "href": "presentations/random_forest/apresentacao.html#importâncias",
    "title": "Técnica Random Forest em árvores de decisão",
    "section": "Importâncias",
    "text": "Importâncias\n\nPodemos verificar a importância de cada variável para o modelo.\n\n\n\n\nvarImpPlot(rf,\n           sort = T,\n           n.var = 10,\n           main = \"Top 10 - Variable Importance\")\n\n\n\n\n\n\n\nimportance(rf)\n\n             MeanDecreaseGini\nSepal.Length         7.299621\nSepal.Width          2.006132\nPetal.Length        35.799244\nPetal.Width         27.318058"
  },
  {
    "objectID": "presentations/random_forest/apresentacao.html#implementações",
    "href": "presentations/random_forest/apresentacao.html#implementações",
    "title": "Técnica Random Forest em árvores de decisão",
    "section": "Implementações",
    "text": "Implementações\n\nUma rotina de classificação via Random forest poderia ser executada de forma análoga em python da seguinte forma:\n\n\n\n\nlibrary(reticulate)\n\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import datasets\n\niris = datasets.load_iris()\ndados = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n\n\nX = dados\ny = iris.target\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n\n\n\nmodel = RandomForestClassifier()\nmodel.fit(X_train, y_train)\n\nRandomForestClassifier()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RandomForestClassifierRandomForestClassifier()\n\ny_pred = model.predict(X_test)\nconfusion_matrix(y_test, y_pred)\n\narray([[15,  0,  0],\n       [ 0, 12,  2],\n       [ 0,  0, 16]], dtype=int64)"
  },
  {
    "objectID": "presentations/random_forest/apresentacao.html#definições",
    "href": "presentations/random_forest/apresentacao.html#definições",
    "title": "Técnica Random Forest em árvores de decisão",
    "section": "Definições",
    "text": "Definições\nAs árvores podem ser representadas como \\(h_1(\\boldsymbol x),\\;  h_2(\\boldsymbol x),\\; . . . ,\\; h_K( \\boldsymbol x)\\) na forma\n\\[ \\{ h \\left( \\boldsymbol x, \\Theta_k \\right), \\; \\; k = 1, \\dots \\}  \\]\nonde \\(\\Theta_k \\; \\text{i.i.d}\\) são vetores aleatórios representando a escolha de \\(p\\) entre os \\(m\\) atributos de \\(\\boldsymbol X\\).\nNormalmente, \\(p \\approx \\sqrt m\\)"
  },
  {
    "objectID": "presentations/random_forest/apresentacao.html#definições-1",
    "href": "presentations/random_forest/apresentacao.html#definições-1",
    "title": "Técnica Random Forest em árvores de decisão",
    "section": "Definições",
    "text": "Definições\n1) A medida em que o número de árvores cresce, a média de acertos se estabiliza e a chance de cometer uma predição errada pode ser quantificada:\n\\[  P_{\\boldsymbol X, Y} \\left(   P_{\\Theta}( h(\\boldsymbol X, \\Theta) = Y)   - P_{\\Theta} (h(\\boldsymbol X, \\Theta)  \\neq Y) &lt; 0\\right) \\]\n\n\\(P_{\\Theta}( h(\\boldsymbol X, \\Theta) = Y)\\) representa a probabilidade de que uma árvore acerte a predição de Y"
  },
  {
    "objectID": "presentations/random_forest/apresentacao.html#definições-2",
    "href": "presentations/random_forest/apresentacao.html#definições-2",
    "title": "Técnica Random Forest em árvores de decisão",
    "section": "Definições",
    "text": "Definições\n2) A acurácia da random forest vai depender do “poder” de cada um dos classificadores individuais e da dependência entre eles.\nUm limite superior para o erro de generalização é dado por\n\\[PE^* \\le -\\bar \\rho(1 − s^2)/s^2 \\]\nonde:\n\n\\(\\boldsymbol s = E_{\\boldsymbol X, Y} mr({\\boldsymbol X, Y} )\\) é o “poder” das árvores \\(h(\\boldsymbol x, \\Theta)\\)\n\\(\\bar \\rho\\) pode ser entendido como a média entre as correlações das árvores."
  },
  {
    "objectID": "presentations/random_forest/apresentacao.html#exemplo-alzheimer",
    "href": "presentations/random_forest/apresentacao.html#exemplo-alzheimer",
    "title": "Técnica Random Forest em árvores de decisão",
    "section": "Exemplo Alzheimer",
    "text": "Exemplo Alzheimer\nO dataset DARWIN (https://archive.ics.uci.edu/dataset/732/darwin) contém dados sobre a escrita a mão de pessoas afetadas pelo Alzheimer e de um grupo de controle, totalizando 174 observações. São 450 variáveis e o objetivo é distinguir pessoas afetadas (P) de pessoas saudáveis (H).\n\n\n\nset.seed(123)\n\nrf_model &lt;- randomForest(\n  class ~ ., data = train_data, \n  ntree = 500, \n  importance = TRUE\n  )\n\n\nNo. of variables tried at each split: 21\nOOB estimate of  error rate: 13.57%\n\nConfusion matrix:\n   H  P class.error\nH 58 10   0.1470588\nP  9 63   0.1250000\n\n\n   H  P class.error\nH 58 10   0.1470588\nP  8 64   0.1111111\n\n\n[1] \"Test error:8.82%\""
  },
  {
    "objectID": "presentations/random_forest/apresentacao.html#section",
    "href": "presentations/random_forest/apresentacao.html#section",
    "title": "Técnica Random Forest em árvores de decisão",
    "section": "",
    "text": "No gráfico abaixo é possível perceber como a escolha do número de variáveis em cada split faz diferença para o resultado final do modelo.\n\n\n\n\n\n\n\n\n\n\nAinda, podemos verficiar a acurácia do modelo pelo número de árvores:"
  },
  {
    "objectID": "presentations/random_forest/apresentacao.html#robustez-a-dados-contaminados",
    "href": "presentations/random_forest/apresentacao.html#robustez-a-dados-contaminados",
    "title": "Técnica Random Forest em árvores de decisão",
    "section": "Robustez a Dados Contaminados",
    "text": "Robustez a Dados Contaminados\nUma das vantagens das florestas aleatórias é sua robustez a pontos atípicos, ou outliers. O exemplo a seguir demonstra a robustez desses modelos a contaminações, além de compará-los a outros métodos de classificação:\n\npacman::p_load(randomForest)\npacman::p_load(caret,e1071,VGAM)\n\niris &lt;- iris %&gt;%\n  mutate(cor = ifelse(Species == \"setosa\",1,ifelse(Species == \"versicolor\",2,3)))\n\nset.seed(150167636)\nind &lt;- sample(2, nrow(iris), replace = TRUE,\n              prob = c(0.7, 0.3))\ntrain &lt;- iris[ind==1,]\ntest &lt;- iris[ind==2,]\n\n\n\ni=4 #Número de pontos contaminados\ndadosPoluidos1 &lt;- train[train$cor==1,]\ndadosPoluidos1 &lt;- dadosPoluidos1[sample(1:nrow(dadosPoluidos1),i,replace = F),]\n\ndadosPoluidos2 &lt;- train[train$cor==3,]\ndadosPoluidos2 &lt;- dadosPoluidos2[sample(1:nrow(dadosPoluidos2),i,replace = F),]\n\ndadosPoluidos1$Petal.Length &lt;- dadosPoluidos1$Petal.Length + 5\ndadosPoluidos1$Petal.Width &lt;- dadosPoluidos1$Petal.Width + 1.7\n\ndadosPoluidos2$Petal.Length &lt;- dadosPoluidos2$Petal.Length - 4\ndadosPoluidos2$Petal.Width &lt;- dadosPoluidos2$Petal.Width - 1.2\n\nDadosExempOutTreino &lt;- rbind(train,dadosPoluidos1,dadosPoluidos2)\n#DadosExempOutTreino &lt;- DadosExempOutTreino[,-6]"
  },
  {
    "objectID": "presentations/random_forest/apresentacao.html#robustez-a-dados-contaminados-1",
    "href": "presentations/random_forest/apresentacao.html#robustez-a-dados-contaminados-1",
    "title": "Técnica Random Forest em árvores de decisão",
    "section": "Robustez a Dados Contaminados",
    "text": "Robustez a Dados Contaminados"
  },
  {
    "objectID": "presentations/random_forest/apresentacao.html#robustez-a-dados-contaminados-2",
    "href": "presentations/random_forest/apresentacao.html#robustez-a-dados-contaminados-2",
    "title": "Técnica Random Forest em árvores de decisão",
    "section": "Robustez a Dados Contaminados",
    "text": "Robustez a Dados Contaminados\n\n\n\nRandom Forest\n\n\n\nConfusion Matrix and Statistics\n\n            Reference\nPrediction   setosa versicolor virginica\n  setosa         17          0         0\n  versicolor      0         10         2\n  virginica       0          1        10\n\nOverall Statistics\n                                          \n               Accuracy : 0.925           \n                 95% CI : (0.7961, 0.9843)\n    No Information Rate : 0.425           \n    P-Value [Acc &gt; NIR] : 3.546e-11       \n                                          \n                  Kappa : 0.8854          \n                                          \n Mcnemar's Test P-Value : NA              \n\nStatistics by Class:\n\n                     Class: setosa Class: versicolor Class: virginica\nSensitivity                  1.000            0.9091           0.8333\nSpecificity                  1.000            0.9310           0.9643\nPos Pred Value               1.000            0.8333           0.9091\nNeg Pred Value               1.000            0.9643           0.9310\nPrevalence                   0.425            0.2750           0.3000\nDetection Rate               0.425            0.2500           0.2500\nDetection Prevalence         0.425            0.3000           0.2750\nBalanced Accuracy            1.000            0.9201           0.8988\n\n\n\n\nRegressão logística\n\n\n\nConfusion Matrix and Statistics\n\n            Reference\nPrediction   setosa versicolor virginica\n  setosa         17          0         0\n  versicolor      0          6         1\n  virginica       0          5        11\n\nOverall Statistics\n                                          \n               Accuracy : 0.85            \n                 95% CI : (0.7016, 0.9429)\n    No Information Rate : 0.425           \n    P-Value [Acc &gt; NIR] : 3.669e-08       \n                                          \n                  Kappa : 0.7697          \n                                          \n Mcnemar's Test P-Value : NA              \n\nStatistics by Class:\n\n                     Class: setosa Class: versicolor Class: virginica\nSensitivity                  1.000            0.5455           0.9167\nSpecificity                  1.000            0.9655           0.8214\nPos Pred Value               1.000            0.8571           0.6875\nNeg Pred Value               1.000            0.8485           0.9583\nPrevalence                   0.425            0.2750           0.3000\nDetection Rate               0.425            0.1500           0.2750\nDetection Prevalence         0.425            0.1750           0.4000\nBalanced Accuracy            1.000            0.7555           0.8690"
  },
  {
    "objectID": "presentations/random_forest/apresentacao.html#robustez-a-dados-contaminados-3",
    "href": "presentations/random_forest/apresentacao.html#robustez-a-dados-contaminados-3",
    "title": "Técnica Random Forest em árvores de decisão",
    "section": "Robustez a Dados Contaminados",
    "text": "Robustez a Dados Contaminados\n\n\n\nSVM linear\n\n\n\nConfusion Matrix and Statistics\n\n            Reference\nPrediction   setosa versicolor virginica\n  setosa         17          0         0\n  versicolor      0          9         1\n  virginica       0          2        11\n\nOverall Statistics\n                                          \n               Accuracy : 0.925           \n                 95% CI : (0.7961, 0.9843)\n    No Information Rate : 0.425           \n    P-Value [Acc &gt; NIR] : 3.546e-11       \n                                          \n                  Kappa : 0.8852          \n                                          \n Mcnemar's Test P-Value : NA              \n\nStatistics by Class:\n\n                     Class: setosa Class: versicolor Class: virginica\nSensitivity                  1.000            0.8182           0.9167\nSpecificity                  1.000            0.9655           0.9286\nPos Pred Value               1.000            0.9000           0.8462\nNeg Pred Value               1.000            0.9333           0.9630\nPrevalence                   0.425            0.2750           0.3000\nDetection Rate               0.425            0.2250           0.2750\nDetection Prevalence         0.425            0.2500           0.3250\nBalanced Accuracy            1.000            0.8918           0.9226\n\n\n\n\nSVM radial\n\n\n\nConfusion Matrix and Statistics\n\n            Reference\nPrediction   setosa versicolor virginica\n  setosa         17          0         0\n  versicolor      0         10         1\n  virginica       0          1        11\n\nOverall Statistics\n                                          \n               Accuracy : 0.95            \n                 95% CI : (0.8308, 0.9939)\n    No Information Rate : 0.425           \n    P-Value [Acc &gt; NIR] : 2.026e-12       \n                                          \n                  Kappa : 0.9235          \n                                          \n Mcnemar's Test P-Value : NA              \n\nStatistics by Class:\n\n                     Class: setosa Class: versicolor Class: virginica\nSensitivity                  1.000            0.9091           0.9167\nSpecificity                  1.000            0.9655           0.9643\nPos Pred Value               1.000            0.9091           0.9167\nNeg Pred Value               1.000            0.9655           0.9643\nPrevalence                   0.425            0.2750           0.3000\nDetection Rate               0.425            0.2500           0.2750\nDetection Prevalence         0.425            0.2750           0.3000\nBalanced Accuracy            1.000            0.9373           0.9405"
  },
  {
    "objectID": "presentations/random_forest/apresentacao.html#robustez-a-dados-contaminados-4",
    "href": "presentations/random_forest/apresentacao.html#robustez-a-dados-contaminados-4",
    "title": "Técnica Random Forest em árvores de decisão",
    "section": "Robustez a Dados Contaminados",
    "text": "Robustez a Dados Contaminados\nComparando robustez de modelos com observações contaminadas\nSem contaminações"
  },
  {
    "objectID": "presentations/random_forest/apresentacao.html#robustez-a-dados-contaminados-5",
    "href": "presentations/random_forest/apresentacao.html#robustez-a-dados-contaminados-5",
    "title": "Técnica Random Forest em árvores de decisão",
    "section": "Robustez a Dados Contaminados",
    "text": "Robustez a Dados Contaminados\n\n\n2 contaminações\n\n\n\n\n\n\n\n\n\n\n4 contaminações"
  },
  {
    "objectID": "presentations/random_forest/apresentacao.html#robustez-a-dados-contaminados-6",
    "href": "presentations/random_forest/apresentacao.html#robustez-a-dados-contaminados-6",
    "title": "Técnica Random Forest em árvores de decisão",
    "section": "Robustez a Dados Contaminados",
    "text": "Robustez a Dados Contaminados\n\n\n6 contaminações\n\n\n\n\n\n\n\n\n\n\n8 contaminações"
  },
  {
    "objectID": "presentations/random_forest/apresentacao.html#vantagens-e-desvantagens-1",
    "href": "presentations/random_forest/apresentacao.html#vantagens-e-desvantagens-1",
    "title": "Técnica Random Forest em árvores de decisão",
    "section": "Vantagens e desvantagens",
    "text": "Vantagens e desvantagens\n\nsobre classificação por florestas aleatórias:\n\n\n\nVantagens\n\n\nRobusto contra overfitting;\nTrabalha bem com dados de alta dimesão;\nConsegue captar relações não-lineares nos dados;\nFornece uma medida de importância;\nRobusto contra outliers e ruídos;\nConsegue lidar com dados faltantes.\n\n\n\nDesvantagens\n\n\nDificil interpretação;\nNão adequado para dados escassos;\nDemora para fazer predições;\nRequer ajuste de hiper-parâmetros."
  }
]